---
permalink: /W05/
---
[HOME](../)

<br>
# Top 10 List of Week 05

1. [Virtual Address](https://docs.microsoft.com/en-us/windows-hardware/drivers/gettingstarted/virtual-address-spaces) <br>
  When a processor reads or writes to a memory location, it uses a virtual address. As part of the read or write operation, the processor translates the virtual address to a physical address. Accessing memory through a virtual address has these advantages:
    - A program can use a contiguous range of virtual addresses to access a large memory buffer that is not contiguous in physical memory.
    - A program can use a range of virtual addresses to access a memory buffer that is larger than the available physical memory. As the supply of physical memory becomes small, the memory manager saves pages of physical memory (typically 4 kilobytes in size) to a disk file. Pages of data or code are moved between physical memory and the disk as needed.
    - The virtual addresses used by different processes are isolated from each other. The code in one process cannot alter the physical memory that is being used by another process or the operating system.

2. [Locality of Reference](https://www.geeksforgeeks.org/locality-of-reference-and-cache-operation-in-cache-memory/) <br>
  Locality of reference refers to a phenomenon in which a computer program tends to access same set of memory locations for a particular time period. In other words, Locality of Reference refers to the tendency of the computer program to access instructions whose addresses are near one another. The property of locality of reference is mainly shown by loops and subroutine calls in a program.

3. [Cache Memory](https://www.geeksforgeeks.org/cache-memory-in-computer-organization/) <br>
  Cache Memory is a special very high-speed memory. It is used to speed up and synchronizing with high-speed CPU. Cache memory is costlier than main memory or disk memory but economical than CPU registers. Cache memory is an extremely fast memory type that acts as a buffer between RAM and the CPU. It holds frequently requested data and instructions so that they are immediately available to the CPU when needed.
  
4. [Swap Space](https://www.geeksforgeeks.org/swap-space-in-operating-system/) <br>
  A computer has sufficient amount of physical memory but most of times we need more so we swap some memory on disk. Swap space is a space on hard disk which is a substitute of physical memory. It is used as virtual memory which contains process memory image. Whenever our computer run short of physical memory it uses it’s virtual memory and stores information in memory on disk. Swap space helps the computer’s operating system in pretending that it have more RAM than it actually has. It is also called as swap file.This interchange of data between virtual memory and real memory is called as swapping and space on disk as “swap space”.
  
5. [Multilevel Cache Organisation](https://www.geeksforgeeks.org/multilevel-cache-organisation/) <br>
  Cache is a random access memory used by the CPU to reduce the average time taken to access memory.
  Multilevel Caches is one of the techniques to improve Cache Performance by reducing the “MISS PENALTY”. Miss Penalty refers to the extra time required to bring the data into cache from the Main memory whenever there is a “miss” in cache .
  
6. [Types of Cache Misses](https://www.geeksforgeeks.org/types-of-cache-misses/) <br>
  Cache Miss occurs when data is not available in the Cache Memory. When the CPU detects a miss, it processes the miss by fetching requested data from main memory.
  Types of Cache misses :
    - Compulsory Miss –
    It is also known as cold start misses or first references misses. These misses occur when the first access to a block happens. Block must be brought into the cache.
    - Capacity Miss –
    These misses occur when the program working set is much larger than the cache capacity. Since Cache can not contain all blocks needed for program execution, so cache discards these blocks.
    - Conflict Miss –
    It is also known as collision misses or interference misses. These misses occur when several blocks are mapped to the same set or block frame.These misses occur in the set associative or direct mapped block placement strategies.
    - Coherence Miss –
    It is also known as Invalidation. These misses occur when other external processors, i.e., I/O updates memory.
  
7. [Stack Machine](https://www.geeksforgeeks.org/stack-machine-in-computer-organisation/) <br>
  In the stack machine, data is available at the top of the stack by default. The stack acts as a source and destination, push and pop instructions are used to access instructions and data from the stack. There is no need to pass the source and destination address because the default address is top of the stack. In the stack machine, there is no need to pass explicit addresses in the instruction. Therefore the instruction format consists only of the OPCODE (Operation Code) field. This instruction format is known as Zero address instruction.
  
8. [Page Fault](https://techterms.com/definition/page_fault) <br>
  A page fault occurs when a program attempts to access a block of memory that is not stored in the physical memory, or RAM. The fault notifies the operating system that it must locate the data in virtual memory, then transfer it from the storage device, such as an HDD or SSD, to the system RAM.
  
9. [Copy on Write](https://www.geeksforgeeks.org/copy-on-write/) <br>
  Copy on Write or simply COW is a resource management technique. One of its main use is in the implementation of the fork system call in which it shares the virtual memory(pages) of the OS.
  In UNIX like OS, fork() system call creates a duplicate process of the parent process which is called as the child process.
  
10. [Over Allocation](https://www.techopedia.com/definition/30867/over-allocation) <br>
  Over-allocation generally refers to situations where resources are allocated at excessive levels. In the context of IT, the resources often refer to hardware or software capabilities such as processing power, memory, data management, bandwidth or other specifications. However, another very common use of the term involves resources to which too many jobs have been allocated, for example, a processor that is dealing with an excessive number of job commands.
  
